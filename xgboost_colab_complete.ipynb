{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete XGBoost In-Domain vs Out-Domain Analysis\n",
    "\n",
    "This notebook automatically sets up everything needed and runs the complete analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Clone repository and install packages\n",
    "import os\n",
    "\n",
    "# Clone repository if not already present\n",
    "if not os.path.exists('/content/tabicl'):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/cliu238/tabicl.git\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"Repository already exists.\")\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/tabicl\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nInstalling packages...\")\n",
    "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn plotly -q\n",
    "print(\"Packages installed!\")\n",
    "\n",
    "# Verify data files exist\n",
    "print(\"\\nChecking data files:\")\n",
    "!ls -lh processed_data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seed\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset\n",
    "df = pd.read_csv('processed_data/adult_numeric_20250729_155457.csv')\n",
    "\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nüè• Sites distribution:\")\n",
    "print(df['site'].value_counts())\n",
    "print(f\"\\nüéØ Target (va34): {df['va34'].nunique()} unique classes\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "print(\"üîß Preprocessing data...\")\n",
    "\n",
    "# Drop cod5 column\n",
    "if 'cod5' in df.columns:\n",
    "    df = df.drop('cod5', axis=1)\n",
    "    print(\"‚úÖ Dropped 'cod5' column\")\n",
    "\n",
    "# Separate features, target, and sites\n",
    "X = df.drop(['va34', 'site'], axis=1)\n",
    "y = df['va34']\n",
    "sites = df['site']\n",
    "\n",
    "print(f\"\\nüìê Data shapes:\")\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")\n",
    "print(f\"Sites: {sites.unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize site distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Site sample counts\n",
    "site_counts = df['site'].value_counts()\n",
    "ax1.bar(site_counts.index, site_counts.values, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax1.set_title('Samples per Site', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.set_xlabel('Site')\n",
    "for i, (site, count) in enumerate(site_counts.items()):\n",
    "    ax1.text(i, count + 20, str(count), ha='center', fontweight='bold')\n",
    "\n",
    "# Classes per site\n",
    "classes_per_site = df.groupby('site')['va34'].nunique().sort_index()\n",
    "ax2.bar(classes_per_site.index, classes_per_site.values, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "ax2.set_title('Unique Classes per Site', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Unique Classes')\n",
    "ax2.set_xlabel('Site')\n",
    "for i, (site, count) in enumerate(classes_per_site.items()):\n",
    "    ax2.text(i, count + 0.5, str(count), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_splits(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"Create train/test splits for each site\"\"\"\n",
    "    domain_splits = {}\n",
    "    \n",
    "    for site in df['site'].unique():\n",
    "        site_data = df[df['site'] == site]\n",
    "        X_site = site_data.drop(['va34', 'site'], axis=1)\n",
    "        y_site = site_data['va34']\n",
    "        \n",
    "        # Handle small sites\n",
    "        if len(site_data) < 50:\n",
    "            domain_splits[site] = {\n",
    "                'X_train': X_site, 'X_test': X_site[:10],\n",
    "                'y_train': y_site, 'y_test': y_site[:10],\n",
    "                'full_X': X_site, 'full_y': y_site\n",
    "            }\n",
    "        else:\n",
    "            # Try stratified split, fall back to regular if needed\n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_site, y_site, test_size=test_size, \n",
    "                    random_state=random_state, stratify=y_site\n",
    "                )\n",
    "            except:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_site, y_site, test_size=test_size, random_state=random_state\n",
    "                )\n",
    "            \n",
    "            domain_splits[site] = {\n",
    "                'X_train': X_train, 'X_test': X_test,\n",
    "                'y_train': y_train, 'y_test': y_test,\n",
    "                'full_X': X_site, 'full_y': y_site\n",
    "            }\n",
    "    \n",
    "    return domain_splits\n",
    "\n",
    "def train_xgboost_model(X_train, y_train):\n",
    "    \"\"\"Train XGBoost with regularization\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(np.unique(y_train_encoded)),\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    return model, le\n",
    "\n",
    "def evaluate_model(model, le, X_test, y_test):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    try:\n",
    "        y_test_encoded = le.transform(y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy_score(y_test_encoded, y_pred),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_test_encoded, y_pred),\n",
    "            'f1_macro': f1_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
    "        }\n",
    "    except:\n",
    "        return {'accuracy': 0.0, 'balanced_accuracy': 0.0, 'f1_macro': 0.0}\n",
    "\n",
    "print(\"‚úÖ Functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä In-Domain Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create domain splits\n",
    "print(\"Creating domain splits...\")\n",
    "domain_data = create_domain_splits(df)\n",
    "\n",
    "print(\"\\nüìÅ Domain splits created:\")\n",
    "for site, data in domain_data.items():\n",
    "    print(f\"{site:10} - Train: {len(data['X_train']):4}, Test: {len(data['X_test']):4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-domain performance evaluation\n",
    "print(\"üéØ Evaluating In-Domain Performance...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "in_domain_results = {}\n",
    "\n",
    "for site in domain_data.keys():\n",
    "    print(f\"\\nTraining for {site}...\")\n",
    "    \n",
    "    # Train on site's data\n",
    "    model, le = train_xgboost_model(\n",
    "        domain_data[site]['X_train'], \n",
    "        domain_data[site]['y_train']\n",
    "    )\n",
    "    \n",
    "    # Test on same site\n",
    "    results = evaluate_model(\n",
    "        model, le,\n",
    "        domain_data[site]['X_test'],\n",
    "        domain_data[site]['y_test']\n",
    "    )\n",
    "    \n",
    "    in_domain_results[site] = results\n",
    "    in_domain_results[site]['model'] = model\n",
    "    in_domain_results[site]['le'] = le\n",
    "    \n",
    "    print(f\"  ‚úì Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"  ‚úì Balanced Acc: {results['balanced_accuracy']:.4f}\")\n",
    "    print(f\"  ‚úì F1 Macro: {results['f1_macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize in-domain results\n",
    "sites_list = list(in_domain_results.keys())\n",
    "accuracies = [in_domain_results[s]['accuracy'] for s in sites_list]\n",
    "balanced_accs = [in_domain_results[s]['balanced_accuracy'] for s in sites_list]\n",
    "f1_scores = [in_domain_results[s]['f1_macro'] for s in sites_list]\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(sites_list))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width, accuracies, width, label='Accuracy', color='#2E7D32', alpha=0.8)\n",
    "bars2 = ax.bar(x, balanced_accs, width, label='Balanced Accuracy', color='#1976D2', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, f1_scores, width, label='F1 Macro', color='#F57C00', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Site', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('In-Domain Performance by Site', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sites_list)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Out-Domain Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-domain performance evaluation\n",
    "print(\"üîÑ Evaluating Out-Domain Performance...\")\n",
    "print(\"(Train on one site, test on others)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "out_domain_results = {}\n",
    "\n",
    "for train_site in domain_data.keys():\n",
    "    out_domain_results[train_site] = {}\n",
    "    \n",
    "    # Train on full data from one site\n",
    "    print(f\"\\nTraining on {train_site}...\")\n",
    "    model, le = train_xgboost_model(\n",
    "        domain_data[train_site]['full_X'],\n",
    "        domain_data[train_site]['full_y']\n",
    "    )\n",
    "    \n",
    "    # Test on all other sites\n",
    "    for test_site in domain_data.keys():\n",
    "        if train_site == test_site:\n",
    "            continue\n",
    "            \n",
    "        results = evaluate_model(\n",
    "            model, le,\n",
    "            domain_data[test_site]['full_X'],\n",
    "            domain_data[test_site]['full_y']\n",
    "        )\n",
    "        \n",
    "        out_domain_results[train_site][test_site] = results\n",
    "        print(f\"  {train_site} ‚Üí {test_site}: {results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out-domain performance matrix\n",
    "sites_list = list(domain_data.keys())\n",
    "n_sites = len(sites_list)\n",
    "out_matrix = np.zeros((n_sites, n_sites))\n",
    "\n",
    "for i, train_site in enumerate(sites_list):\n",
    "    for j, test_site in enumerate(sites_list):\n",
    "        if train_site == test_site:\n",
    "            out_matrix[i, j] = in_domain_results[train_site]['accuracy']\n",
    "        else:\n",
    "            out_matrix[i, j] = out_domain_results[train_site][test_site]['accuracy']\n",
    "\n",
    "# Visualize matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(out_matrix, annot=True, fmt='.3f', \n",
    "            xticklabels=sites_list, yticklabels=sites_list,\n",
    "            cmap='RdYlGn', vmin=0, vmax=1, \n",
    "            cbar_kws={'label': 'Accuracy'},\n",
    "            linewidths=0.5, linecolor='gray')\n",
    "\n",
    "plt.title('Domain Transfer Performance Matrix\\n(Train ‚Üí Test)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Train Site', fontsize=12)\n",
    "plt.xlabel('Test Site', fontsize=12)\n",
    "\n",
    "# Highlight diagonal (in-domain)\n",
    "for i in range(n_sites):\n",
    "    plt.gca().add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='blue', lw=3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Blue boxes = In-domain performance (diagonal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Cross-Domain Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-domain performance evaluation\n",
    "print(\"üåê Evaluating Cross-Domain Performance...\")\n",
    "print(\"(Train on multiple sites, test on held-out)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cross_domain_results = {}\n",
    "\n",
    "for held_out_site in domain_data.keys():\n",
    "    # Combine all other sites for training\n",
    "    train_sites = [s for s in domain_data.keys() if s != held_out_site]\n",
    "    \n",
    "    X_train_list = [domain_data[s]['full_X'] for s in train_sites]\n",
    "    y_train_list = [domain_data[s]['full_y'] for s in train_sites]\n",
    "    \n",
    "    X_train_combined = pd.concat(X_train_list, axis=0)\n",
    "    y_train_combined = pd.concat(y_train_list, axis=0)\n",
    "    \n",
    "    print(f\"\\nTraining on {', '.join(train_sites)}\")\n",
    "    print(f\"  Combined training size: {len(X_train_combined)} samples\")\n",
    "    \n",
    "    # Train model\n",
    "    model, le = train_xgboost_model(X_train_combined, y_train_combined)\n",
    "    \n",
    "    # Test on held-out site\n",
    "    results = evaluate_model(\n",
    "        model, le,\n",
    "        domain_data[held_out_site]['full_X'],\n",
    "        domain_data[held_out_site]['full_y']\n",
    "    )\n",
    "    \n",
    "    cross_domain_results[held_out_site] = results\n",
    "    cross_domain_results[held_out_site]['model'] = model\n",
    "    cross_domain_results[held_out_site]['train_sites'] = train_sites\n",
    "    \n",
    "    print(f\"  Testing on {held_out_site}: {results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance comparison\n",
    "sites_list = list(domain_data.keys())\n",
    "\n",
    "# Collect metrics\n",
    "performance_data = []\n",
    "\n",
    "for site in sites_list:\n",
    "    # In-domain\n",
    "    performance_data.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'In-Domain',\n",
    "        'Accuracy': in_domain_results[site]['accuracy']\n",
    "    })\n",
    "    \n",
    "    # Out-domain average\n",
    "    out_accs = [out_domain_results[train][site]['accuracy'] \n",
    "               for train in sites_list if train != site]\n",
    "    performance_data.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Out-Domain (Avg)',\n",
    "        'Accuracy': np.mean(out_accs) if out_accs else 0\n",
    "    })\n",
    "    \n",
    "    # Cross-domain\n",
    "    performance_data.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Cross-Domain',\n",
    "        'Accuracy': cross_domain_results[site]['accuracy']\n",
    "    })\n",
    "\n",
    "df_perf = pd.DataFrame(performance_data)\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig = px.bar(df_perf, x='Site', y='Accuracy', color='Scenario',\n",
    "             title='Performance Comparison: In-Domain vs Out-Domain vs Cross-Domain',\n",
    "             barmode='group', height=500,\n",
    "             color_discrete_map={\n",
    "                 'In-Domain': '#2E7D32',\n",
    "                 'Out-Domain (Avg)': '#F57C00', \n",
    "                 'Cross-Domain': '#1976D2'\n",
    "             })\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis_range=[0, 1],\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nüìä Performance Summary:\")\n",
    "pivot_table = df_perf.pivot(index='Site', columns='Scenario', values='Accuracy')\n",
    "print(pivot_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ Domain Shift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze domain shift effects\n",
    "domain_shift_data = {}\n",
    "\n",
    "for site in sites_list:\n",
    "    in_acc = in_domain_results[site]['accuracy']\n",
    "    cross_acc = cross_domain_results[site]['accuracy']\n",
    "    \n",
    "    # Average out-domain when this site is test\n",
    "    out_accs = [out_domain_results[train][site]['accuracy'] \n",
    "               for train in sites_list if train != site]\n",
    "    avg_out_acc = np.mean(out_accs) if out_accs else 0\n",
    "    \n",
    "    domain_shift_data[site] = {\n",
    "        'In-Domain': in_acc,\n",
    "        'Cross-Domain': cross_acc,\n",
    "        'Out-Domain (Avg)': avg_out_acc,\n",
    "        'In‚ÜíCross Drop': in_acc - cross_acc,\n",
    "        'In‚ÜíOut Drop': in_acc - avg_out_acc,\n",
    "        'Relative Drop (%)': ((in_acc - cross_acc) / in_acc * 100) if in_acc > 0 else 0\n",
    "    }\n",
    "\n",
    "df_shift = pd.DataFrame(domain_shift_data).T\n",
    "\n",
    "# Visualize domain shift\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Performance drops\n",
    "x = np.arange(len(sites_list))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, df_shift['In‚ÜíCross Drop'], width, \n",
    "           label='In‚ÜíCross Drop', color='#FF6B6B', alpha=0.7)\n",
    "axes[0].bar(x + width/2, df_shift['In‚ÜíOut Drop'], width,\n",
    "           label='In‚ÜíOut Drop', color='#4ECDC4', alpha=0.7)\n",
    "axes[0].set_xlabel('Site', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy Drop', fontsize=12)\n",
    "axes[0].set_title('Performance Degradation due to Domain Shift', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(sites_list)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Absolute performance\n",
    "axes[1].plot(sites_list, df_shift['In-Domain'], 'o-', \n",
    "            label='In-Domain', linewidth=2, markersize=8, color='#2E7D32')\n",
    "axes[1].plot(sites_list, df_shift['Cross-Domain'], 's-',\n",
    "            label='Cross-Domain', linewidth=2, markersize=8, color='#1976D2')\n",
    "axes[1].plot(sites_list, df_shift['Out-Domain (Avg)'], '^-',\n",
    "            label='Out-Domain (Avg)', linewidth=2, markersize=8, color='#F57C00')\n",
    "axes[1].set_xlabel('Site', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Absolute Performance Across Scenarios', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Domain Shift Analysis:\")\n",
    "print(df_shift.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final report\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"XGBOOST DOMAIN ANALYSIS FINAL REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate overall statistics\n",
    "in_domain_avg = np.mean([in_domain_results[s]['accuracy'] for s in sites_list])\n",
    "cross_domain_avg = np.mean([cross_domain_results[s]['accuracy'] for s in sites_list])\n",
    "\n",
    "out_domain_all = []\n",
    "for train in sites_list:\n",
    "    for test in sites_list:\n",
    "        if train != test:\n",
    "            out_domain_all.append(out_domain_results[train][test]['accuracy'])\n",
    "out_domain_avg = np.mean(out_domain_all)\n",
    "\n",
    "print(f\"\\nüìä DATASET OVERVIEW:\")\n",
    "print(f\"  ‚Ä¢ Total samples: {len(df):,}\")\n",
    "print(f\"  ‚Ä¢ Number of features: {X.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Number of classes: {y.nunique()}\")\n",
    "print(f\"  ‚Ä¢ Number of sites: {len(sites_list)}\")\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "print(f\"  ‚Ä¢ Average In-Domain Accuracy:    {in_domain_avg:.4f}\")\n",
    "print(f\"  ‚Ä¢ Average Cross-Domain Accuracy: {cross_domain_avg:.4f}\")\n",
    "print(f\"  ‚Ä¢ Average Out-Domain Accuracy:   {out_domain_avg:.4f}\")\n",
    "\n",
    "print(f\"\\nüìâ PERFORMANCE DEGRADATION:\")\n",
    "drop_in_cross = in_domain_avg - cross_domain_avg\n",
    "drop_in_out = in_domain_avg - out_domain_avg\n",
    "print(f\"  ‚Ä¢ In-Domain ‚Üí Cross-Domain: -{drop_in_cross:.4f} ({drop_in_cross/in_domain_avg*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ In-Domain ‚Üí Out-Domain:   -{drop_in_out:.4f} ({drop_in_out/in_domain_avg*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST & WORST PERFORMERS:\")\n",
    "best_in = max(sites_list, key=lambda x: in_domain_results[x]['accuracy'])\n",
    "worst_in = min(sites_list, key=lambda x: in_domain_results[x]['accuracy'])\n",
    "best_cross = max(sites_list, key=lambda x: cross_domain_results[x]['accuracy'])\n",
    "worst_cross = min(sites_list, key=lambda x: cross_domain_results[x]['accuracy'])\n",
    "\n",
    "print(f\"  In-Domain:\")\n",
    "print(f\"    ‚Ä¢ Best:  {best_in} ({in_domain_results[best_in]['accuracy']:.4f})\")\n",
    "print(f\"    ‚Ä¢ Worst: {worst_in} ({in_domain_results[worst_in]['accuracy']:.4f})\")\n",
    "print(f\"  Cross-Domain:\")\n",
    "print(f\"    ‚Ä¢ Best:  {best_cross} ({cross_domain_results[best_cross]['accuracy']:.4f})\")\n",
    "print(f\"    ‚Ä¢ Worst: {worst_cross} ({cross_domain_results[worst_cross]['accuracy']:.4f})\")\n",
    "\n",
    "# Find best/worst transfer pairs\n",
    "best_pair = None\n",
    "best_score = 0\n",
    "worst_pair = None\n",
    "worst_score = 1\n",
    "\n",
    "for train in sites_list:\n",
    "    for test in sites_list:\n",
    "        if train != test:\n",
    "            score = out_domain_results[train][test]['accuracy']\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_pair = (train, test)\n",
    "            if score < worst_score:\n",
    "                worst_score = score\n",
    "                worst_pair = (train, test)\n",
    "\n",
    "print(f\"\\nüîÑ DOMAIN TRANSFER PAIRS:\")\n",
    "print(f\"  ‚Ä¢ Best transfer:  {best_pair[0]} ‚Üí {best_pair[1]} ({best_score:.4f})\")\n",
    "print(f\"  ‚Ä¢ Worst transfer: {worst_pair[0]} ‚Üí {worst_pair[1]} ({worst_score:.4f})\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"  1. Cross-domain training improves over single-domain by {(cross_domain_avg - out_domain_avg):.4f}\")\n",
    "print(f\"  2. Average domain shift causes {drop_in_cross/in_domain_avg*100:.1f}% performance drop\")\n",
    "print(f\"  3. Site '{best_cross}' shows best robustness to domain shift\")\n",
    "print(f\"  4. Site '{worst_cross}' is most affected by domain shift\")\n",
    "\n",
    "if best_score > 0.5:\n",
    "    print(f\"  5. Sites '{best_pair[0]}' and '{best_pair[1]}' have good domain similarity\")\n",
    "else:\n",
    "    print(f\"  5. Significant distribution shift exists across all domain pairs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save results\n",
    "save = input(\"\\nSave results to CSV? (y/n): \").lower() == 'y'\n",
    "\n",
    "if save:\n",
    "    import os\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    # Save performance summary\n",
    "    df_perf.to_csv('results/performance_summary.csv', index=False)\n",
    "    df_shift.to_csv('results/domain_shift_analysis.csv')\n",
    "    \n",
    "    # Save transfer matrix\n",
    "    pd.DataFrame(out_matrix, index=sites_list, columns=sites_list).to_csv(\n",
    "        'results/transfer_matrix.csv'\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Results saved to 'results/' directory\")\n",
    "else:\n",
    "    print(\"Results not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}