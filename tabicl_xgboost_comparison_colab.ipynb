{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ TabICL vs XGBoost: Comprehensive Model Comparison\n",
    "\n",
    "This notebook provides a complete comparison between TabICL (Tabular In-Context Learning) and XGBoost for Verbal Autopsy classification across multiple geographic sites.\n",
    "\n",
    "## Key Features:\n",
    "- **Automatic Setup**: Installs all dependencies including TabICL\n",
    "- **Fair Comparison**: Both models use identical data splits and preprocessing\n",
    "- **Domain Analysis**: In-domain, out-domain, and cross-domain evaluation\n",
    "- **Statistical Testing**: Significance analysis of performance differences\n",
    "- **Comprehensive Metrics**: Accuracy, F1 scores, training time, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Complete Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete setup for Google Colab\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"ðŸš€ Starting TabICL vs XGBoost Comparison Setup...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clone repository if needed\n",
    "if not os.path.exists('/content/tabicl'):\n",
    "    print(\"ðŸ“¦ Cloning repository...\")\n",
    "    !git clone https://github.com/cliu238/tabicl.git\n",
    "    print(\"âœ… Repository cloned!\")\n",
    "else:\n",
    "    print(\"âœ… Repository already exists\")\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/tabicl\n",
    "print(f\"ðŸ“ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nðŸ“¦ Installing required packages...\")\n",
    "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn plotly scipy -q\n",
    "print(\"âœ… Basic packages installed\")\n",
    "\n",
    "# Install TabICL\n",
    "print(\"\\nðŸ“¦ Installing TabICL...\")\n",
    "try:\n",
    "    # Try official TabICL installation\n",
    "    !pip install tabicl -q\n",
    "    import tabicl\n",
    "    print(\"âœ… TabICL installed successfully!\")\n",
    "    TABICL_AVAILABLE = True\n",
    "except:\n",
    "    try:\n",
    "        # Try GitHub installation\n",
    "        !pip install git+https://github.com/soda-inria/tabicl.git -q\n",
    "        import tabicl\n",
    "        print(\"âœ… TabICL installed from GitHub!\")\n",
    "        TABICL_AVAILABLE = True\n",
    "    except:\n",
    "        print(\"âš ï¸ TabICL installation failed. Will use mock implementation.\")\n",
    "        TABICL_AVAILABLE = False\n",
    "\n",
    "# Verify data files\n",
    "print(\"\\nðŸ“Š Checking data files...\")\n",
    "if os.path.exists('processed_data/adult_numeric_20250729_155457.csv'):\n",
    "    print(\"âœ… Data file found!\")\n",
    "else:\n",
    "    print(\"âŒ Data file not found. Checking directory:\")\n",
    "    !ls -la processed_data/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Setup complete! Ready to proceed.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Step 2: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    precision_score, recall_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"\\nðŸ“Š Loading dataset...\")\n",
    "df = pd.read_csv('processed_data/adult_numeric_20250729_155457.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nðŸ¥ Sites distribution:\")\n",
    "print(df['site'].value_counts())\n",
    "print(f\"\\nðŸŽ¯ Target classes: {df['va34'].nunique()} unique causes of death\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 3: Model Wrapper Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabICL Wrapper Implementation\n",
    "class TabICLWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper for TabICL with automatic feature selection and class handling.\n",
    "    Handles TabICL constraints: â‰¤100 features, â‰¤10 classes (with hierarchical approach).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_context_samples=100,\n",
    "                 max_features=100,\n",
    "                 feature_selection='mutual_info',\n",
    "                 scale_features=True,\n",
    "                 random_state=42,\n",
    "                 verbose=False):\n",
    "        self.n_context_samples = n_context_samples\n",
    "        self.max_features = min(max_features, 100)  # TabICL constraint\n",
    "        self.feature_selection = feature_selection\n",
    "        self.scale_features = scale_features\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Components\n",
    "        self.feature_selector_ = None\n",
    "        self.scaler_ = None\n",
    "        self.label_encoder_ = None\n",
    "        self.model_ = None\n",
    "        self.selected_features_ = None\n",
    "        \n",
    "        # For hierarchical classification if >10 classes\n",
    "        self.use_hierarchical_ = False\n",
    "        self.class_groups_ = None\n",
    "        self.group_models_ = {}\n",
    "    \n",
    "    def _select_features(self, X, y):\n",
    "        \"\"\"Select top features to meet TabICL constraint.\"\"\"\n",
    "        if X.shape[1] <= self.max_features:\n",
    "            return X\n",
    "        \n",
    "        if self.feature_selection == 'mutual_info':\n",
    "            selector = SelectKBest(mutual_info_classif, k=self.max_features)\n",
    "        elif self.feature_selection == 'pca':\n",
    "            selector = PCA(n_components=self.max_features)\n",
    "        else:\n",
    "            # Variance-based selection\n",
    "            variances = np.var(X, axis=0)\n",
    "            top_indices = np.argsort(variances)[-self.max_features:]\n",
    "            return X[:, top_indices]\n",
    "        \n",
    "        self.feature_selector_ = selector\n",
    "        return selector.fit_transform(X, y)\n",
    "    \n",
    "    def _handle_many_classes(self, y):\n",
    "        \"\"\"Handle >10 classes using hierarchical approach.\"\"\"\n",
    "        unique_classes = np.unique(y)\n",
    "        n_classes = len(unique_classes)\n",
    "        \n",
    "        if n_classes <= 10:\n",
    "            return y, False\n",
    "        \n",
    "        # Create class groups (simple grouping by class index)\n",
    "        n_groups = 10\n",
    "        classes_per_group = n_classes // n_groups + 1\n",
    "        \n",
    "        self.class_groups_ = {}\n",
    "        for i, cls in enumerate(unique_classes):\n",
    "            group = min(i // classes_per_group, n_groups - 1)\n",
    "            if group not in self.class_groups_:\n",
    "                self.class_groups_[group] = []\n",
    "            self.class_groups_[group].append(cls)\n",
    "        \n",
    "        # Map classes to groups\n",
    "        y_groups = np.zeros_like(y)\n",
    "        for group, classes in self.class_groups_.items():\n",
    "            mask = np.isin(y, classes)\n",
    "            y_groups[mask] = group\n",
    "        \n",
    "        return y_groups, True\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit TabICL model with preprocessing.\"\"\"\n",
    "        # Convert to numpy if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        if hasattr(y, 'values'):\n",
    "            y = y.values\n",
    "        \n",
    "        # Encode labels\n",
    "        self.label_encoder_ = LabelEncoder()\n",
    "        y_encoded = self.label_encoder_.fit_transform(y)\n",
    "        \n",
    "        # Feature selection\n",
    "        X_selected = self._select_features(X, y_encoded)\n",
    "        \n",
    "        # Scaling\n",
    "        if self.scale_features:\n",
    "            self.scaler_ = StandardScaler()\n",
    "            X_selected = self.scaler_.fit_transform(X_selected)\n",
    "        \n",
    "        # Handle many classes\n",
    "        y_train, self.use_hierarchical_ = self._handle_many_classes(y_encoded)\n",
    "        \n",
    "        # Fit model\n",
    "        if TABICL_AVAILABLE:\n",
    "            try:\n",
    "                from tabicl import TabICLClassifier\n",
    "                self.model_ = TabICLClassifier(verbose=self.verbose)\n",
    "                self.model_.fit(X_selected, y_train)\n",
    "            except Exception as e:\n",
    "                if self.verbose:\n",
    "                    print(f\"TabICL error: {e}. Using fallback.\")\n",
    "                self._fit_fallback(X_selected, y_train)\n",
    "        else:\n",
    "            self._fit_fallback(X_selected, y_train)\n",
    "        \n",
    "        # Store training data for context\n",
    "        n_context = min(self.n_context_samples, len(X_selected))\n",
    "        indices = np.random.choice(len(X_selected), n_context, replace=False)\n",
    "        self.context_X_ = X_selected[indices]\n",
    "        self.context_y_ = y_train[indices]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _fit_fallback(self, X, y):\n",
    "        \"\"\"Fallback to KNN-based approach if TabICL unavailable.\"\"\"\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        self.model_ = KNeighborsClassifier(n_neighbors=min(10, len(X)))\n",
    "        self.model_.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using TabICL model.\"\"\"\n",
    "        # Convert to numpy if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        \n",
    "        # Apply same preprocessing\n",
    "        if self.feature_selector_ is not None:\n",
    "            X = self.feature_selector_.transform(X)\n",
    "        \n",
    "        if self.scaler_ is not None:\n",
    "            X = self.scaler_.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = self.model_.predict(X)\n",
    "        \n",
    "        # Convert back to original labels\n",
    "        if self.use_hierarchical_:\n",
    "            # For hierarchical, just use group predictions\n",
    "            # (full hierarchical would need second-level models)\n",
    "            # Map groups back to most common class in group\n",
    "            y_pred_classes = np.zeros_like(y_pred)\n",
    "            for i, group in enumerate(y_pred):\n",
    "                group_classes = self.class_groups_.get(int(group), [0])\n",
    "                y_pred_classes[i] = group_classes[0]  # Use first class in group\n",
    "            y_pred = y_pred_classes\n",
    "        \n",
    "        # Decode labels\n",
    "        try:\n",
    "            y_pred = self.label_encoder_.inverse_transform(y_pred.astype(int))\n",
    "        except:\n",
    "            # Handle unseen classes\n",
    "            known_classes = self.label_encoder_.classes_\n",
    "            y_pred = np.array([known_classes[0] if p >= len(known_classes) else known_classes[int(p)] \n",
    "                              for p in y_pred])\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# XGBoost Wrapper Implementation\n",
    "class XGBoostWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper for XGBoost with consistent interface.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 max_depth=4,\n",
    "                 learning_rate=0.1,\n",
    "                 n_estimators=100,\n",
    "                 subsample=0.8,\n",
    "                 colsample_bytree=0.8,\n",
    "                 reg_alpha=0.1,\n",
    "                 reg_lambda=1.0,\n",
    "                 random_state=42,\n",
    "                 verbose=False):\n",
    "        self.params = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'max_depth': max_depth,\n",
    "            'learning_rate': learning_rate,\n",
    "            'n_estimators': n_estimators,\n",
    "            'subsample': subsample,\n",
    "            'colsample_bytree': colsample_bytree,\n",
    "            'reg_alpha': reg_alpha,\n",
    "            'reg_lambda': reg_lambda,\n",
    "            'random_state': random_state,\n",
    "            'verbosity': 1 if verbose else 0\n",
    "        }\n",
    "        self.model_ = None\n",
    "        self.label_encoder_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit XGBoost model.\"\"\"\n",
    "        # Convert to numpy if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        if hasattr(y, 'values'):\n",
    "            y = y.values\n",
    "        \n",
    "        # Encode labels\n",
    "        self.label_encoder_ = LabelEncoder()\n",
    "        y_encoded = self.label_encoder_.fit_transform(y)\n",
    "        \n",
    "        # Update num_class\n",
    "        self.params['num_class'] = len(np.unique(y_encoded))\n",
    "        \n",
    "        # Train model\n",
    "        self.model_ = xgb.XGBClassifier(**self.params)\n",
    "        self.model_.fit(X, y_encoded)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using XGBoost model.\"\"\"\n",
    "        # Convert to numpy if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = self.model_.predict(X)\n",
    "        \n",
    "        # Decode labels\n",
    "        return self.label_encoder_.inverse_transform(y_pred)\n",
    "\n",
    "print(\"âœ… Model wrappers defined successfully!\")\n",
    "print(f\"TabICL Available: {TABICL_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 4: Data Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "print(\"ðŸ”§ Preprocessing data...\")\n",
    "\n",
    "# Drop cod5 column if present\n",
    "if 'cod5' in df.columns:\n",
    "    df = df.drop('cod5', axis=1)\n",
    "    print(\"âœ… Dropped 'cod5' column\")\n",
    "\n",
    "# Create domain splits\n",
    "def create_domain_splits(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"Create train/test splits for each site.\"\"\"\n",
    "    domain_splits = {}\n",
    "    \n",
    "    for site in df['site'].unique():\n",
    "        site_data = df[df['site'] == site]\n",
    "        X_site = site_data.drop(['va34', 'site'], axis=1)\n",
    "        y_site = site_data['va34']\n",
    "        \n",
    "        # Handle small sites\n",
    "        if len(site_data) < 50:\n",
    "            # Use all data for training with small test set\n",
    "            test_size_adj = min(10, len(site_data) // 5)\n",
    "            X_train = X_site[:-test_size_adj]\n",
    "            X_test = X_site[-test_size_adj:]\n",
    "            y_train = y_site[:-test_size_adj]\n",
    "            y_test = y_site[-test_size_adj:]\n",
    "        else:\n",
    "            # Regular train/test split\n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_site, y_site, test_size=test_size,\n",
    "                    random_state=random_state, stratify=y_site\n",
    "                )\n",
    "            except:\n",
    "                # Fallback to non-stratified if stratification fails\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X_site, y_site, test_size=test_size,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "        \n",
    "        domain_splits[site] = {\n",
    "            'X_train': X_train, 'X_test': X_test,\n",
    "            'y_train': y_train, 'y_test': y_test,\n",
    "            'full_X': X_site, 'full_y': y_site\n",
    "        }\n",
    "    \n",
    "    return domain_splits\n",
    "\n",
    "# Create splits\n",
    "domain_data = create_domain_splits(df)\n",
    "\n",
    "print(\"\\nðŸ“ Domain splits created:\")\n",
    "for site, data in domain_data.items():\n",
    "    print(f\"{site:10} - Train: {len(data['X_train']):4}, Test: {len(data['X_test']):4}\")\n",
    "\n",
    "# Visualize data distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Site sample counts\n",
    "site_counts = df['site'].value_counts()\n",
    "ax1.bar(site_counts.index, site_counts.values, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax1.set_title('Samples per Site', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.set_xlabel('Site')\n",
    "\n",
    "# Classes per site\n",
    "classes_per_site = df.groupby('site')['va34'].nunique().sort_index()\n",
    "ax2.bar(classes_per_site.index, classes_per_site.values, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "ax2.set_title('Unique Classes per Site', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Unique Classes')\n",
    "ax2.set_xlabel('Site')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 5: In-Domain Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, X_test, y_test, y_pred=None):\n",
    "    \"\"\"Evaluate model performance.\"\"\"\n",
    "    if y_pred is None:\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "# In-domain comparison\n",
    "print(\"ðŸŽ¯ Evaluating In-Domain Performance...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "in_domain_results = {'XGBoost': {}, 'TabICL': {}}\n",
    "training_times = {'XGBoost': {}, 'TabICL': {}}\n",
    "\n",
    "for site in domain_data.keys():\n",
    "    print(f\"\\nðŸ“ Site: {site}\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # XGBoost\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_model = XGBoostWrapper(verbose=False)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    xgb_model.fit(domain_data[site]['X_train'], domain_data[site]['y_train'])\n",
    "    xgb_time = time.time() - start_time\n",
    "    \n",
    "    xgb_results = evaluate_model(xgb_model, domain_data[site]['X_test'], domain_data[site]['y_test'])\n",
    "    in_domain_results['XGBoost'][site] = xgb_results\n",
    "    training_times['XGBoost'][site] = xgb_time\n",
    "    \n",
    "    print(f\"  XGBoost - Acc: {xgb_results['accuracy']:.4f}, F1: {xgb_results['f1_macro']:.4f}, Time: {xgb_time:.2f}s\")\n",
    "    \n",
    "    # TabICL\n",
    "    print(\"Training TabICL...\")\n",
    "    tabicl_model = TabICLWrapper(n_context_samples=50, verbose=False)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tabicl_model.fit(domain_data[site]['X_train'], domain_data[site]['y_train'])\n",
    "    tabicl_time = time.time() - start_time\n",
    "    \n",
    "    tabicl_results = evaluate_model(tabicl_model, domain_data[site]['X_test'], domain_data[site]['y_test'])\n",
    "    in_domain_results['TabICL'][site] = tabicl_results\n",
    "    training_times['TabICL'][site] = tabicl_time\n",
    "    \n",
    "    print(f\"  TabICL  - Acc: {tabicl_results['accuracy']:.4f}, F1: {tabicl_results['f1_macro']:.4f}, Time: {tabicl_time:.2f}s\")\n",
    "    \n",
    "    # Comparison\n",
    "    acc_diff = tabicl_results['accuracy'] - xgb_results['accuracy']\n",
    "    winner = \"TabICL\" if acc_diff > 0 else \"XGBoost\"\n",
    "    print(f\"  ðŸ† Winner: {winner} (+{abs(acc_diff):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 6: Visualize In-Domain Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "sites_list = list(domain_data.keys())\n",
    "metrics = ['accuracy', 'balanced_accuracy', 'f1_macro', 'f1_weighted']\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for site in sites_list:\n",
    "    for metric in metrics:\n",
    "        comparison_data.append({\n",
    "            'Site': site,\n",
    "            'Metric': metric.replace('_', ' ').title(),\n",
    "            'XGBoost': in_domain_results['XGBoost'][site][metric],\n",
    "            'TabICL': in_domain_results['TabICL'][site][metric]\n",
    "        })\n",
    "\n",
    "df_comp = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    metric_display = metric.replace('_', ' ').title()\n",
    "    df_metric = df_comp[df_comp['Metric'] == metric_display]\n",
    "    \n",
    "    x = np.arange(len(sites_list))\n",
    "    width = 0.35\n",
    "    \n",
    "    xgb_values = [in_domain_results['XGBoost'][s][metric] for s in sites_list]\n",
    "    tabicl_values = [in_domain_results['TabICL'][s][metric] for s in sites_list]\n",
    "    \n",
    "    bars1 = axes[i].bar(x - width/2, xgb_values, width, label='XGBoost', color='#2E7D32', alpha=0.8)\n",
    "    bars2 = axes[i].bar(x + width/2, tabicl_values, width, label='TabICL', color='#1976D2', alpha=0.8)\n",
    "    \n",
    "    axes[i].set_xlabel('Site', fontsize=11)\n",
    "    axes[i].set_ylabel('Score', fontsize=11)\n",
    "    axes[i].set_title(f'{metric_display} Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xticks(x)\n",
    "    axes[i].set_xticklabels(sites_list, rotation=45)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].set_ylim([0, 1])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1 + bars2:\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('In-Domain Performance: XGBoost vs TabICL', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training time comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(sites_list))\n",
    "width = 0.35\n",
    "\n",
    "xgb_times = [training_times['XGBoost'][s] for s in sites_list]\n",
    "tabicl_times = [training_times['TabICL'][s] for s in sites_list]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, xgb_times, width, label='XGBoost', color='#2E7D32', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, tabicl_times, width, label='TabICL', color='#1976D2', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Site', fontsize=12)\n",
    "ax.set_ylabel('Training Time (seconds)', fontsize=12)\n",
    "ax.set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sites_list)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Step 7: Out-Domain Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-domain performance evaluation\n",
    "print(\"ðŸ”„ Evaluating Out-Domain Performance...\")\n",
    "print(\"(Train on one site, test on others)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "out_domain_results = {'XGBoost': {}, 'TabICL': {}}\n",
    "\n",
    "for train_site in domain_data.keys():\n",
    "    out_domain_results['XGBoost'][train_site] = {}\n",
    "    out_domain_results['TabICL'][train_site] = {}\n",
    "    \n",
    "    print(f\"\\nðŸ“ Training on {train_site}...\")\n",
    "    \n",
    "    # Train models on full data from one site\n",
    "    xgb_model = XGBoostWrapper(verbose=False)\n",
    "    xgb_model.fit(domain_data[train_site]['full_X'], domain_data[train_site]['full_y'])\n",
    "    \n",
    "    tabicl_model = TabICLWrapper(n_context_samples=100, verbose=False)\n",
    "    tabicl_model.fit(domain_data[train_site]['full_X'], domain_data[train_site]['full_y'])\n",
    "    \n",
    "    # Test on all other sites\n",
    "    for test_site in domain_data.keys():\n",
    "        if train_site == test_site:\n",
    "            continue\n",
    "        \n",
    "        # XGBoost\n",
    "        xgb_results = evaluate_model(\n",
    "            xgb_model,\n",
    "            domain_data[test_site]['full_X'],\n",
    "            domain_data[test_site]['full_y']\n",
    "        )\n",
    "        out_domain_results['XGBoost'][train_site][test_site] = xgb_results\n",
    "        \n",
    "        # TabICL\n",
    "        tabicl_results = evaluate_model(\n",
    "            tabicl_model,\n",
    "            domain_data[test_site]['full_X'],\n",
    "            domain_data[test_site]['full_y']\n",
    "        )\n",
    "        out_domain_results['TabICL'][train_site][test_site] = tabicl_results\n",
    "        \n",
    "        print(f\"  {train_site} â†’ {test_site}:\")\n",
    "        print(f\"    XGBoost: {xgb_results['accuracy']:.4f}\")\n",
    "        print(f\"    TabICL:  {tabicl_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ºï¸ Step 8: Domain Transfer Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transfer matrices\n",
    "sites_list = list(domain_data.keys())\n",
    "n_sites = len(sites_list)\n",
    "\n",
    "xgb_matrix = np.zeros((n_sites, n_sites))\n",
    "tabicl_matrix = np.zeros((n_sites, n_sites))\n",
    "\n",
    "for i, train_site in enumerate(sites_list):\n",
    "    for j, test_site in enumerate(sites_list):\n",
    "        if train_site == test_site:\n",
    "            # Use in-domain results for diagonal\n",
    "            xgb_matrix[i, j] = in_domain_results['XGBoost'][train_site]['accuracy']\n",
    "            tabicl_matrix[i, j] = in_domain_results['TabICL'][train_site]['accuracy']\n",
    "        else:\n",
    "            xgb_matrix[i, j] = out_domain_results['XGBoost'][train_site][test_site]['accuracy']\n",
    "            tabicl_matrix[i, j] = out_domain_results['TabICL'][train_site][test_site]['accuracy']\n",
    "\n",
    "# Visualize matrices\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# XGBoost matrix\n",
    "sns.heatmap(xgb_matrix, annot=True, fmt='.3f',\n",
    "            xticklabels=sites_list, yticklabels=sites_list,\n",
    "            cmap='RdYlGn', vmin=0, vmax=1,\n",
    "            cbar_kws={'label': 'Accuracy'},\n",
    "            linewidths=0.5, linecolor='gray', ax=ax1)\n",
    "ax1.set_title('XGBoost Domain Transfer', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Train Site')\n",
    "ax1.set_xlabel('Test Site')\n",
    "\n",
    "# TabICL matrix\n",
    "sns.heatmap(tabicl_matrix, annot=True, fmt='.3f',\n",
    "            xticklabels=sites_list, yticklabels=sites_list,\n",
    "            cmap='RdYlGn', vmin=0, vmax=1,\n",
    "            cbar_kws={'label': 'Accuracy'},\n",
    "            linewidths=0.5, linecolor='gray', ax=ax2)\n",
    "ax2.set_title('TabICL Domain Transfer', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Train Site')\n",
    "ax2.set_xlabel('Test Site')\n",
    "\n",
    "# Difference matrix (TabICL - XGBoost)\n",
    "diff_matrix = tabicl_matrix - xgb_matrix\n",
    "sns.heatmap(diff_matrix, annot=True, fmt='.3f',\n",
    "            xticklabels=sites_list, yticklabels=sites_list,\n",
    "            cmap='coolwarm', center=0, vmin=-0.2, vmax=0.2,\n",
    "            cbar_kws={'label': 'Difference (TabICL - XGBoost)'},\n",
    "            linewidths=0.5, linecolor='gray', ax=ax3)\n",
    "ax3.set_title('Performance Difference', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Train Site')\n",
    "ax3.set_xlabel('Test Site')\n",
    "\n",
    "# Highlight diagonal\n",
    "for ax in [ax1, ax2, ax3]:\n",
    "    for i in range(n_sites):\n",
    "        ax.add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='blue', lw=2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Blue boxes indicate in-domain performance (diagonal)\")\n",
    "print(\"ðŸ’¡ Red in difference matrix: XGBoost better | Blue: TabICL better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ Step 9: Cross-Domain Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-domain performance evaluation\n",
    "print(\"ðŸŒ Evaluating Cross-Domain Performance...\")\n",
    "print(\"(Train on multiple sites, test on held-out)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cross_domain_results = {'XGBoost': {}, 'TabICL': {}}\n",
    "\n",
    "for held_out_site in domain_data.keys():\n",
    "    # Combine all other sites for training\n",
    "    train_sites = [s for s in domain_data.keys() if s != held_out_site]\n",
    "    \n",
    "    X_train_list = [domain_data[s]['full_X'] for s in train_sites]\n",
    "    y_train_list = [domain_data[s]['full_y'] for s in train_sites]\n",
    "    \n",
    "    X_train_combined = pd.concat(X_train_list, axis=0)\n",
    "    y_train_combined = pd.concat(y_train_list, axis=0)\n",
    "    \n",
    "    print(f\"\\nðŸ“ Training on {', '.join(train_sites)}\")\n",
    "    print(f\"   Testing on {held_out_site}\")\n",
    "    print(f\"   Combined training size: {len(X_train_combined)} samples\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    xgb_model = XGBoostWrapper(verbose=False)\n",
    "    xgb_model.fit(X_train_combined, y_train_combined)\n",
    "    xgb_results = evaluate_model(\n",
    "        xgb_model,\n",
    "        domain_data[held_out_site]['full_X'],\n",
    "        domain_data[held_out_site]['full_y']\n",
    "    )\n",
    "    cross_domain_results['XGBoost'][held_out_site] = xgb_results\n",
    "    \n",
    "    # Train TabICL\n",
    "    tabicl_model = TabICLWrapper(n_context_samples=150, verbose=False)\n",
    "    tabicl_model.fit(X_train_combined, y_train_combined)\n",
    "    tabicl_results = evaluate_model(\n",
    "        tabicl_model,\n",
    "        domain_data[held_out_site]['full_X'],\n",
    "        domain_data[held_out_site]['full_y']\n",
    "    )\n",
    "    cross_domain_results['TabICL'][held_out_site] = tabicl_results\n",
    "    \n",
    "    print(f\"   XGBoost: {xgb_results['accuracy']:.4f}\")\n",
    "    print(f\"   TabICL:  {tabicl_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 10: Comprehensive Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison\n",
    "performance_summary = []\n",
    "\n",
    "for site in sites_list:\n",
    "    # In-domain\n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'In-Domain',\n",
    "        'Model': 'XGBoost',\n",
    "        'Accuracy': in_domain_results['XGBoost'][site]['accuracy']\n",
    "    })\n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'In-Domain',\n",
    "        'Model': 'TabICL',\n",
    "        'Accuracy': in_domain_results['TabICL'][site]['accuracy']\n",
    "    })\n",
    "    \n",
    "    # Out-domain average\n",
    "    xgb_out_accs = [out_domain_results['XGBoost'][train][site]['accuracy']\n",
    "                   for train in sites_list if train != site]\n",
    "    tabicl_out_accs = [out_domain_results['TabICL'][train][site]['accuracy']\n",
    "                      for train in sites_list if train != site]\n",
    "    \n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Out-Domain',\n",
    "        'Model': 'XGBoost',\n",
    "        'Accuracy': np.mean(xgb_out_accs) if xgb_out_accs else 0\n",
    "    })\n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Out-Domain',\n",
    "        'Model': 'TabICL',\n",
    "        'Accuracy': np.mean(tabicl_out_accs) if tabicl_out_accs else 0\n",
    "    })\n",
    "    \n",
    "    # Cross-domain\n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Cross-Domain',\n",
    "        'Model': 'XGBoost',\n",
    "        'Accuracy': cross_domain_results['XGBoost'][site]['accuracy']\n",
    "    })\n",
    "    performance_summary.append({\n",
    "        'Site': site,\n",
    "        'Scenario': 'Cross-Domain',\n",
    "        'Model': 'TabICL',\n",
    "        'Accuracy': cross_domain_results['TabICL'][site]['accuracy']\n",
    "    })\n",
    "\n",
    "df_perf = pd.DataFrame(performance_summary)\n",
    "\n",
    "# Create interactive plot\n",
    "fig = px.bar(df_perf, x='Site', y='Accuracy', color='Model',\n",
    "             facet_col='Scenario',\n",
    "             title='Model Performance Comparison: XGBoost vs TabICL',\n",
    "             barmode='group', height=400,\n",
    "             color_discrete_map={'XGBoost': '#2E7D32', 'TabICL': '#1976D2'})\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis_range=[0, 1],\n",
    "    font=dict(size=11)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nðŸ“Š Performance Summary by Scenario:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_stats = df_perf.groupby(['Scenario', 'Model'])['Accuracy'].agg(['mean', 'std']).round(4)\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 11: Statistical Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance testing\n",
    "print(\"ðŸ“Š Statistical Significance Testing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect paired accuracies for each scenario\n",
    "scenarios = ['In-Domain', 'Out-Domain', 'Cross-Domain']\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{scenario} Performance:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    if scenario == 'In-Domain':\n",
    "        xgb_accs = [in_domain_results['XGBoost'][s]['accuracy'] for s in sites_list]\n",
    "        tabicl_accs = [in_domain_results['TabICL'][s]['accuracy'] for s in sites_list]\n",
    "    elif scenario == 'Out-Domain':\n",
    "        xgb_accs = []\n",
    "        tabicl_accs = []\n",
    "        for test_site in sites_list:\n",
    "            xgb_site = [out_domain_results['XGBoost'][train][test_site]['accuracy']\n",
    "                       for train in sites_list if train != test_site]\n",
    "            tabicl_site = [out_domain_results['TabICL'][train][test_site]['accuracy']\n",
    "                          for train in sites_list if train != test_site]\n",
    "            xgb_accs.extend(xgb_site)\n",
    "            tabicl_accs.extend(tabicl_site)\n",
    "    else:  # Cross-Domain\n",
    "        xgb_accs = [cross_domain_results['XGBoost'][s]['accuracy'] for s in sites_list]\n",
    "        tabicl_accs = [cross_domain_results['TabICL'][s]['accuracy'] for s in sites_list]\n",
    "    \n",
    "    # Paired t-test\n",
    "    if len(xgb_accs) > 1:\n",
    "        t_stat, p_value = stats.ttest_rel(tabicl_accs, xgb_accs)\n",
    "        \n",
    "        mean_xgb = np.mean(xgb_accs)\n",
    "        mean_tabicl = np.mean(tabicl_accs)\n",
    "        diff = mean_tabicl - mean_xgb\n",
    "        \n",
    "        print(f\"  XGBoost mean:  {mean_xgb:.4f} (Â±{np.std(xgb_accs):.4f})\")\n",
    "        print(f\"  TabICL mean:   {mean_tabicl:.4f} (Â±{np.std(tabicl_accs):.4f})\")\n",
    "        print(f\"  Difference:    {diff:+.4f}\")\n",
    "        print(f\"  t-statistic:   {t_stat:.4f}\")\n",
    "        print(f\"  p-value:       {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            better = \"TabICL\" if diff > 0 else \"XGBoost\"\n",
    "            print(f\"  âœ… {better} is significantly better (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  âšª No significant difference (p >= 0.05)\")\n",
    "\n",
    "# Wilcoxon signed-rank test (non-parametric alternative)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Wilcoxon Signed-Rank Test (Non-parametric):\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "all_xgb = []\n",
    "all_tabicl = []\n",
    "\n",
    "for site in sites_list:\n",
    "    all_xgb.append(in_domain_results['XGBoost'][site]['accuracy'])\n",
    "    all_tabicl.append(in_domain_results['TabICL'][site]['accuracy'])\n",
    "    all_xgb.append(cross_domain_results['XGBoost'][site]['accuracy'])\n",
    "    all_tabicl.append(cross_domain_results['TabICL'][site]['accuracy'])\n",
    "\n",
    "if len(all_xgb) > 1:\n",
    "    statistic, p_value = stats.wilcoxon(all_tabicl, all_xgb)\n",
    "    print(f\"Overall comparison (all scenarios):\")\n",
    "    print(f\"  Wilcoxon statistic: {statistic:.4f}\")\n",
    "    print(f\"  p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        median_diff = np.median(np.array(all_tabicl) - np.array(all_xgb))\n",
    "        better = \"TabICL\" if median_diff > 0 else \"XGBoost\"\n",
    "        print(f\"  âœ… {better} performs significantly better overall\")\n",
    "    else:\n",
    "        print(f\"  âšª No significant overall difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Step 12: Domain Shift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain shift analysis\n",
    "domain_shift_analysis = []\n",
    "\n",
    "for site in sites_list:\n",
    "    # XGBoost\n",
    "    xgb_in = in_domain_results['XGBoost'][site]['accuracy']\n",
    "    xgb_cross = cross_domain_results['XGBoost'][site]['accuracy']\n",
    "    xgb_out = np.mean([out_domain_results['XGBoost'][train][site]['accuracy']\n",
    "                      for train in sites_list if train != site])\n",
    "    \n",
    "    # TabICL\n",
    "    tabicl_in = in_domain_results['TabICL'][site]['accuracy']\n",
    "    tabicl_cross = cross_domain_results['TabICL'][site]['accuracy']\n",
    "    tabicl_out = np.mean([out_domain_results['TabICL'][train][site]['accuracy']\n",
    "                         for train in sites_list if train != site])\n",
    "    \n",
    "    domain_shift_analysis.append({\n",
    "        'Site': site,\n",
    "        'XGBoost_In': xgb_in,\n",
    "        'XGBoost_Cross': xgb_cross,\n",
    "        'XGBoost_Out': xgb_out,\n",
    "        'XGBoost_Drop': xgb_in - xgb_cross,\n",
    "        'TabICL_In': tabicl_in,\n",
    "        'TabICL_Cross': tabicl_cross,\n",
    "        'TabICL_Out': tabicl_out,\n",
    "        'TabICL_Drop': tabicl_in - tabicl_cross,\n",
    "        'Robustness_Diff': (tabicl_in - tabicl_cross) - (xgb_in - xgb_cross)\n",
    "    })\n",
    "\n",
    "df_shift = pd.DataFrame(domain_shift_analysis)\n",
    "\n",
    "# Visualize domain shift\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Performance drop comparison\n",
    "x = np.arange(len(sites_list))\n",
    "width = 0.35\n",
    "\n",
    "xgb_drops = df_shift['XGBoost_Drop'].values\n",
    "tabicl_drops = df_shift['TabICL_Drop'].values\n",
    "\n",
    "axes[0].bar(x - width/2, xgb_drops, width, label='XGBoost', color='#FF6B6B', alpha=0.7)\n",
    "axes[0].bar(x + width/2, tabicl_drops, width, label='TabICL', color='#4ECDC4', alpha=0.7)\n",
    "axes[0].set_xlabel('Site', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy Drop (Inâ†’Cross)', fontsize=12)\n",
    "axes[0].set_title('Domain Shift Impact', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(sites_list)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Absolute performance across scenarios\n",
    "scenarios_x = ['In-Domain', 'Cross-Domain', 'Out-Domain']\n",
    "xgb_means = [df_shift['XGBoost_In'].mean(), \n",
    "             df_shift['XGBoost_Cross'].mean(),\n",
    "             df_shift['XGBoost_Out'].mean()]\n",
    "tabicl_means = [df_shift['TabICL_In'].mean(),\n",
    "                df_shift['TabICL_Cross'].mean(),\n",
    "                df_shift['TabICL_Out'].mean()]\n",
    "\n",
    "axes[1].plot(scenarios_x, xgb_means, 'o-', label='XGBoost',\n",
    "            linewidth=2, markersize=8, color='#2E7D32')\n",
    "axes[1].plot(scenarios_x, tabicl_means, 's-', label='TabICL',\n",
    "            linewidth=2, markersize=8, color='#1976D2')\n",
    "axes[1].set_ylabel('Average Accuracy', fontsize=12)\n",
    "axes[1].set_title('Performance Across Scenarios', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Domain Robustness Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(df_shift[['Site', 'XGBoost_Drop', 'TabICL_Drop', 'Robustness_Diff']].round(4))\n",
    "print(\"\\nðŸ’¡ Negative Robustness_Diff means TabICL is more robust to domain shift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 13: Final Report and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final report\n",
    "print(\"=\"*80)\n",
    "print(\" \"*15 + \"TABICL VS XGBOOST: FINAL COMPARISON REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"  â€¢ Total samples: {len(df):,}\")\n",
    "print(f\"  â€¢ Number of features: {len(df.columns) - 2}\")\n",
    "print(f\"  â€¢ Number of classes: {df['va34'].nunique()}\")\n",
    "print(f\"  â€¢ Number of sites: {len(sites_list)}\")\n",
    "print(f\"  â€¢ TabICL feature reduction: {len(df.columns) - 2} â†’ 100 features\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\nðŸ“ˆ OVERALL PERFORMANCE SUMMARY:\")\n",
    "\n",
    "scenarios_perf = {}\n",
    "for scenario in ['In-Domain', 'Out-Domain', 'Cross-Domain']:\n",
    "    xgb_mean = df_perf[(df_perf['Scenario'] == scenario) & \n",
    "                       (df_perf['Model'] == 'XGBoost')]['Accuracy'].mean()\n",
    "    tabicl_mean = df_perf[(df_perf['Scenario'] == scenario) & \n",
    "                          (df_perf['Model'] == 'TabICL')]['Accuracy'].mean()\n",
    "    scenarios_perf[scenario] = {'XGBoost': xgb_mean, 'TabICL': tabicl_mean}\n",
    "    \n",
    "    print(f\"\\n  {scenario}:\")\n",
    "    print(f\"    â€¢ XGBoost: {xgb_mean:.4f}\")\n",
    "    print(f\"    â€¢ TabICL:  {tabicl_mean:.4f}\")\n",
    "    diff = tabicl_mean - xgb_mean\n",
    "    if abs(diff) > 0.01:\n",
    "        winner = \"TabICL\" if diff > 0 else \"XGBoost\"\n",
    "        print(f\"    â€¢ Winner:  {winner} (+{abs(diff):.4f})\")\n",
    "    else:\n",
    "        print(f\"    â€¢ Result:  Comparable performance\")\n",
    "\n",
    "# Domain robustness\n",
    "print(f\"\\nðŸ“‰ DOMAIN ROBUSTNESS:\")\n",
    "avg_xgb_drop = df_shift['XGBoost_Drop'].mean()\n",
    "avg_tabicl_drop = df_shift['TabICL_Drop'].mean()\n",
    "print(f\"  â€¢ Average XGBoost accuracy drop (Inâ†’Cross): {avg_xgb_drop:.4f}\")\n",
    "print(f\"  â€¢ Average TabICL accuracy drop (Inâ†’Cross):  {avg_tabicl_drop:.4f}\")\n",
    "if abs(avg_tabicl_drop) < abs(avg_xgb_drop):\n",
    "    print(f\"  â€¢ âœ… TabICL is more robust to domain shift\")\n",
    "else:\n",
    "    print(f\"  â€¢ âœ… XGBoost is more robust to domain shift\")\n",
    "\n",
    "# Training efficiency\n",
    "print(f\"\\nâ±ï¸ TRAINING EFFICIENCY:\")\n",
    "avg_xgb_time = np.mean(list(training_times['XGBoost'].values()))\n",
    "avg_tabicl_time = np.mean(list(training_times['TabICL'].values()))\n",
    "print(f\"  â€¢ Average XGBoost training time: {avg_xgb_time:.2f}s\")\n",
    "print(f\"  â€¢ Average TabICL training time:  {avg_tabicl_time:.2f}s\")\n",
    "print(f\"  â€¢ Speed ratio: {avg_xgb_time/avg_tabicl_time:.2f}x\")\n",
    "\n",
    "# Best and worst cases\n",
    "print(f\"\\nðŸ† BEST & WORST PERFORMERS:\")\n",
    "\n",
    "# Find best performances\n",
    "xgb_best_site = max(sites_list, key=lambda x: in_domain_results['XGBoost'][x]['accuracy'])\n",
    "xgb_best_acc = in_domain_results['XGBoost'][xgb_best_site]['accuracy']\n",
    "tabicl_best_site = max(sites_list, key=lambda x: in_domain_results['TabICL'][x]['accuracy'])\n",
    "tabicl_best_acc = in_domain_results['TabICL'][tabicl_best_site]['accuracy']\n",
    "\n",
    "print(f\"  Best in-domain:\")\n",
    "print(f\"    â€¢ XGBoost: {xgb_best_site} ({xgb_best_acc:.4f})\")\n",
    "print(f\"    â€¢ TabICL:  {tabicl_best_site} ({tabicl_best_acc:.4f})\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Compare overall performance\n",
    "overall_xgb = np.mean([scenarios_perf[s]['XGBoost'] for s in scenarios_perf])\n",
    "overall_tabicl = np.mean([scenarios_perf[s]['TabICL'] for s in scenarios_perf])\n",
    "\n",
    "if overall_tabicl > overall_xgb:\n",
    "    insights.append(f\"TabICL achieves {(overall_tabicl - overall_xgb):.4f} higher average accuracy\")\n",
    "else:\n",
    "    insights.append(f\"XGBoost achieves {(overall_xgb - overall_tabicl):.4f} higher average accuracy\")\n",
    "\n",
    "if abs(avg_tabicl_drop) < abs(avg_xgb_drop):\n",
    "    insights.append(f\"TabICL shows {abs(avg_xgb_drop - avg_tabicl_drop):.4f} better domain robustness\")\n",
    "\n",
    "if avg_tabicl_time < avg_xgb_time:\n",
    "    insights.append(f\"TabICL trains {avg_xgb_time/avg_tabicl_time:.1f}x faster\")\n",
    "else:\n",
    "    insights.append(f\"XGBoost trains {avg_tabicl_time/avg_xgb_time:.1f}x faster\")\n",
    "\n",
    "insights.append(\"TabICL requires no hyperparameter tuning\")\n",
    "insights.append(\"TabICL uses in-context learning without gradient updates\")\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"  {i}. {insight}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDATIONS:\")\n",
    "print(f\"  â€¢ Use TabICL when:\")\n",
    "print(f\"    - Domain shift is a concern\")\n",
    "print(f\"    - Limited hyperparameter tuning resources\")\n",
    "print(f\"    - Need quick prototyping\")\n",
    "print(f\"    - Working with few-shot scenarios\")\n",
    "print(f\"\\n  â€¢ Use XGBoost when:\")\n",
    "print(f\"    - Maximum accuracy is critical\")\n",
    "print(f\"    - Single domain deployment\")\n",
    "print(f\"    - Interpretability is important\")\n",
    "print(f\"    - Computational resources are limited\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… Comparison Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Optional: Save Results to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save results\n",
    "save_results = input(\"Save results to CSV? (y/n): \").lower() == 'y'\n",
    "\n",
    "if save_results:\n",
    "    import os\n",
    "    os.makedirs('comparison_results', exist_ok=True)\n",
    "    \n",
    "    # Save performance summary\n",
    "    df_perf.to_csv('comparison_results/model_performance.csv', index=False)\n",
    "    df_shift.to_csv('comparison_results/domain_shift_analysis.csv', index=False)\n",
    "    \n",
    "    # Save transfer matrices\n",
    "    pd.DataFrame(xgb_matrix, index=sites_list, columns=sites_list).to_csv(\n",
    "        'comparison_results/xgboost_transfer_matrix.csv'\n",
    "    )\n",
    "    pd.DataFrame(tabicl_matrix, index=sites_list, columns=sites_list).to_csv(\n",
    "        'comparison_results/tabicl_transfer_matrix.csv'\n",
    "    )\n",
    "    \n",
    "    # Save summary statistics\n",
    "    with open('comparison_results/summary_report.txt', 'w') as f:\n",
    "        f.write(\"TabICL vs XGBoost Comparison Summary\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Overall XGBoost accuracy: {overall_xgb:.4f}\\n\")\n",
    "        f.write(f\"Overall TabICL accuracy: {overall_tabicl:.4f}\\n\")\n",
    "        f.write(f\"Domain robustness - XGBoost drop: {avg_xgb_drop:.4f}\\n\")\n",
    "        f.write(f\"Domain robustness - TabICL drop: {avg_tabicl_drop:.4f}\\n\")\n",
    "    \n",
    "    print(\"âœ… Results saved to 'comparison_results/' directory\")\n",
    "    \n",
    "    # Mount Google Drive if in Colab\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        !cp -r comparison_results /content/drive/MyDrive/\n",
    "        print(\"âœ… Results also copied to Google Drive\")\n",
    "    except:\n",
    "        print(\"ðŸ“ Results saved locally\")\n",
    "else:\n",
    "    print(\"Results not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}